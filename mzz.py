# -*- coding: utf-8 -*-
"""MZZ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lhi2h2m_PXrjx1s_ntPE5rM_5YHu0jSA
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# =====================================================
# PAGE CONFIG
# =====================================================
st.set_page_config(page_title="Salary Prediction App", layout="wide")

st.title("üíº Salary Prediction using Random Forest")

# =====================================================
# LOAD DATA
# =====================================================
DATA_PATH = "salary_dataset_2000.csv"

df = pd.read_csv(DATA_PATH)

st.success("Dataset Loaded Successfully!")

with st.expander("üìÑ View Dataset Sample"):
    st.dataframe(df.head(20))

TARGET = "Salary"

# =====================================================
# SPLIT FEATURES & TARGET
# =====================================================
X = df.drop(TARGET, axis=1)
y = df[TARGET]

num_features = X.select_dtypes(include=["int64", "float64"]).columns
cat_features = X.select_dtypes(include=["object"]).columns

# =====================================================
# PREPROCESSING
# =====================================================
numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, num_features),
        ("cat", categorical_transformer, cat_features)
    ]
)

# =====================================================
# TRAIN TEST SPLIT
# =====================================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Remove NaN target rows
train_mask = ~y_train.isna()
test_mask = ~y_test.isna()

X_train = X_train[train_mask]
y_train = y_train[train_mask]

X_test = X_test[test_mask]
y_test = y_test[test_mask]

# =====================================================
# MODEL
# =====================================================
rf_model = RandomForestRegressor(
    n_estimators=400,
    max_depth=15,
    min_samples_split=5,
    random_state=42,
    n_jobs=-1
)

pipe = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", rf_model)
])

# =====================================================
# TRAIN MODEL
# =====================================================
with st.spinner("‚è≥ Training model..."):
    pipe.fit(X_train, y_train)

st.success("‚úÖ Model Trained Successfully!")

# =====================================================
# METRICS
# =====================================================
y_pred = pipe.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

n = X_test.shape[0]
p = X_test.shape[1]
adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)

st.subheader("üìä Model Performance")

col1, col2, col3, col4 = st.columns(4)

col1.metric("MAE", round(mae, 2))
col2.metric("RMSE", round(rmse, 2))
col3.metric("R¬≤", round(r2, 4))
col4.metric("Adj R¬≤", round(adj_r2, 4))

# =====================================================
# VISUALIZATIONS
# =====================================================
st.subheader("üìà Training & Testing Visualizations")

# Training Plot
fig1 = plt.figure()
plt.scatter(y_train, pipe.predict(X_train))
plt.xlabel("Actual Salary (Train)")
plt.ylabel("Predicted Salary (Train)")
plt.title("Training: Actual vs Predicted")
st.pyplot(fig1)

# Testing Plot
fig2 = plt.figure()
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Salary (Test)")
plt.ylabel("Predicted Salary (Test)")
plt.title("Testing: Actual vs Predicted")
st.pyplot(fig2)

# Residuals
fig3 = plt.figure()
plt.hist(y_test - y_pred, bins=30)
plt.xlabel("Residual (Actual - Predicted)")
plt.title("Residual Distribution")
st.pyplot(fig3)

# =====================================================
# üéØ SALARY PREDICTION FORM
# =====================================================
st.subheader("üéØ Predict Salary for a New Employee")

with st.form("prediction_form"):

    input_data = {}

    st.write("### Enter Candidate Details:")

    # Numeric Inputs
    for col in num_features:
        min_val = float(df[col].min())
        max_val = float(df[col].max())
        mean_val = float(df[col].mean())

        input_data[col] = st.number_input(
            f"{col}",
            min_value=min_val,
            max_value=max_val,
            value=mean_val
        )

    # Categorical Inputs (dropdown from dataset)
    for col in cat_features:
        options = sorted(df[col].dropna().unique().tolist())

        input_data[col] = st.selectbox(
            f"{col}",
            options
        )

    submitted = st.form_submit_button("üöÄ Predict Salary")

# =====================================================
# SHOW PREDICTION
# =====================================================
if submitted:

    input_df = pd.DataFrame([input_data])

    prediction = pipe.predict(input_df)[0]

    st.success(f"üí∞ Predicted Salary: ‚Çπ {round(prediction, 2)}")

